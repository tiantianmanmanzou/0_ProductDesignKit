#!/usr/bin/env python3
"""
æ•°æ®åº“è¿ç§»è„šæœ¬åˆ†æå™¨

åˆ†æAlembicè¿ç§»è„šæœ¬ä¸­çš„æšä¸¾å®šä¹‰å’Œæ•°æ®æ“ä½œï¼Œæ£€æŸ¥æ˜¯å¦ä¸ä»£ç å®šä¹‰ä¸€è‡´
è¿™æ˜¯æ£€æŸ¥æ•°æ®åº“schemaå’Œæ•°æ®ä¸€è‡´æ€§çš„é‡è¦å·¥å…·

åŠŸèƒ½ï¼š
1. è§£æAlembicè¿ç§»è„šæœ¬
2. æå–æšä¸¾ç›¸å…³çš„DDLæ“ä½œ
3. æ£€æŸ¥æšä¸¾å€¼è®¾ç½®æ˜¯å¦ç¬¦åˆè§„èŒƒ
4. è¯†åˆ«æ½œåœ¨çš„æ•°æ®ä¸ä¸€è‡´é£é™©
5. ç”Ÿæˆè¿ç§»è„šæœ¬æ”¹è¿›å»ºè®®
"""

import os
import sys
import re
import ast
import json
import argparse
from typing import Dict, List, Set, Tuple, Optional, Any
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

class MigrationScriptAnalyzer:
    """æ•°æ®åº“è¿ç§»è„šæœ¬åˆ†æå™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.backend_root = self.project_root / "backend"
        self.alembic_versions_dir = self.backend_root / "alembic" / "versions"
        
        # åˆ†æç»“æœ
        self.migration_files = []
        self.enum_operations = []
        self.data_operations = []
        self.potential_issues = []
        
        # å·²çŸ¥çš„æšä¸¾ç±»å‹ï¼ˆä»ä»£ç åˆ†æä¸­è·å–ï¼‰
        self.known_enums = {
            'ParseStatusEnum': ['uploaded', 'parsing', 'completed', 'failed'],
            'TaskStatusEnum': ['pending', 'running', 'completed', 'failed'],
            'TaskTypeEnum': ['data_extraction', 'summary_generation', 'module_extraction'],
            'GenerationStatusEnum': ['pending', 'generating', 'completed', 'failed'],
            'SummaryTypeEnum': ['l1_summary', 'l2_summary', 'l3_summary', 'combined_summary'],
            'UserStatusEnum': ['active', 'inactive', 'suspended'],
        }
        
        # æšä¸¾ç›¸å…³çš„SQLæ¨¡å¼
        self.enum_patterns = {
            'create_enum': r"op\.execute\(['\"]CREATE TYPE (\w+) AS ENUM \((.*?)\)['\"]",
            'alter_enum': r"op\.execute\(['\"]ALTER TYPE (\w+) (?:ADD VALUE|RENAME VALUE) (.*?)['\"]",
            'drop_enum': r"op\.execute\(['\"]DROP TYPE (?:IF EXISTS )?(\w+)['\"]",
            'enum_column': r"sa\.Column\(['\"](\w+)['\"], (\w+)(?:\(\))?",
            'update_enum_data': r"op\.execute\(['\"]UPDATE (\w+) SET (\w+) = ['\"]([^'\"]*)['\"] WHERE (\w+) = ['\"]([^'\"]*)['\"]['\"]"
        }

    def find_migration_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰è¿ç§»æ–‡ä»¶"""
        if not self.alembic_versions_dir.exists():
            print(f"âŒ Alembicç‰ˆæœ¬ç›®å½•ä¸å­˜åœ¨: {self.alembic_versions_dir}")
            return []
        
        migration_files = []
        for file_path in self.alembic_versions_dir.glob("*.py"):
            if not file_path.name.startswith("__"):
                migration_files.append(file_path)
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
        migration_files.sort(key=lambda x: x.stat().st_mtime)
        return migration_files

    def parse_migration_file(self, file_path: Path) -> Dict[str, Any]:
        """è§£æå•ä¸ªè¿ç§»æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            migration_info = {
                'file_path': str(file_path.relative_to(self.project_root)),
                'file_name': file_path.name,
                'content': content,
                'revision': self._extract_revision(content),
                'down_revision': self._extract_down_revision(content),
                'enum_operations': [],
                'data_operations': [],
                'potential_issues': []
            }
            
            # è§£ææšä¸¾ç›¸å…³æ“ä½œ
            migration_info['enum_operations'] = self._extract_enum_operations(content)
            migration_info['data_operations'] = self._extract_data_operations(content)
            migration_info['potential_issues'] = self._analyze_potential_issues(migration_info)
            
            return migration_info
            
        except Exception as e:
            print(f"âŒ è§£æè¿ç§»æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {
                'file_path': str(file_path.relative_to(self.project_root)),
                'error': str(e)
            }

    def _extract_revision(self, content: str) -> Optional[str]:
        """æå–revisionä¿¡æ¯"""
        match = re.search(r"revision\s*=\s*['\"]([^'\"]+)['\"]", content)
        return match.group(1) if match else None

    def _extract_down_revision(self, content: str) -> Optional[str]:
        """æå–down_revisionä¿¡æ¯"""
        match = re.search(r"down_revision\s*=\s*['\"]([^'\"]+)['\"]", content)
        return match.group(1) if match else None

    def _extract_enum_operations(self, content: str) -> List[Dict[str, Any]]:
        """æå–æšä¸¾ç›¸å…³æ“ä½œ"""
        enum_ops = []
        
        # åˆ›å»ºæšä¸¾ç±»å‹
        for match in re.finditer(self.enum_patterns['create_enum'], content, re.IGNORECASE | re.DOTALL):
            enum_name = match.group(1)
            enum_values_str = match.group(2)
            enum_values = [v.strip().strip("'\"") for v in enum_values_str.split(',')]
            
            enum_ops.append({
                'operation': 'CREATE_ENUM',
                'enum_name': enum_name,
                'enum_values': enum_values,
                'line': content[:match.start()].count('\n') + 1
            })
        
        # ä¿®æ”¹æšä¸¾ç±»å‹
        for match in re.finditer(self.enum_patterns['alter_enum'], content, re.IGNORECASE):
            enum_name = match.group(1)
            operation_detail = match.group(2)
            
            enum_ops.append({
                'operation': 'ALTER_ENUM',
                'enum_name': enum_name,
                'operation_detail': operation_detail,
                'line': content[:match.start()].count('\n') + 1
            })
        
        # åˆ é™¤æšä¸¾ç±»å‹
        for match in re.finditer(self.enum_patterns['drop_enum'], content, re.IGNORECASE):
            enum_name = match.group(1)
            
            enum_ops.append({
                'operation': 'DROP_ENUM',
                'enum_name': enum_name,
                'line': content[:match.start()].count('\n') + 1
            })
        
        # ä½¿ç”¨æšä¸¾çš„åˆ—å®šä¹‰
        for match in re.finditer(self.enum_patterns['enum_column'], content, re.IGNORECASE):
            column_name = match.group(1)
            column_type = match.group(2)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„æšä¸¾ç±»å‹
            if any(enum_name.lower() in column_type.lower() for enum_name in self.known_enums.keys()):
                enum_ops.append({
                    'operation': 'USE_ENUM_COLUMN',
                    'column_name': column_name,
                    'column_type': column_type,
                    'line': content[:match.start()].count('\n') + 1
                })
        
        return enum_ops

    def _extract_data_operations(self, content: str) -> List[Dict[str, Any]]:
        """æå–æ•°æ®æ“ä½œ"""
        data_ops = []
        
        # UPDATEè¯­å¥ï¼ˆç‰¹åˆ«æ˜¯æšä¸¾å€¼æ›´æ–°ï¼‰
        for match in re.finditer(self.enum_patterns['update_enum_data'], content, re.IGNORECASE):
            table_name = match.group(1)
            column_name = match.group(2)
            new_value = match.group(3)
            old_value = match.group(5)
            
            data_ops.append({
                'operation': 'UPDATE_ENUM_DATA',
                'table_name': table_name,
                'column_name': column_name,
                'old_value': old_value,
                'new_value': new_value,
                'line': content[:match.start()].count('\n') + 1
            })
        
        # é€šç”¨çš„op.executeæ“ä½œ
        execute_pattern = r"op\.execute\(['\"]([^'\"]*(?:UPDATE|INSERT|DELETE)[^'\"]*)['\"]"
        for match in re.finditer(execute_pattern, content, re.IGNORECASE | re.DOTALL):
            sql_statement = match.group(1)
            
            data_ops.append({
                'operation': 'EXECUTE_SQL',
                'sql_statement': sql_statement,
                'line': content[:match.start()].count('\n') + 1
            })
        
        return data_ops

    def _analyze_potential_issues(self, migration_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åˆ†ææ½œåœ¨é—®é¢˜"""
        issues = []
        
        # æ£€æŸ¥æšä¸¾å€¼æ˜¯å¦ç¬¦åˆå°å†™è§„èŒƒ
        for enum_op in migration_info['enum_operations']:
            if enum_op['operation'] == 'CREATE_ENUM':
                enum_name = enum_op['enum_name']
                enum_values = enum_op['enum_values']
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤§å†™å€¼
                uppercase_values = [v for v in enum_values if v != v.lower()]
                if uppercase_values:
                    issues.append({
                        'type': 'ENUM_CASE_VIOLATION',
                        'severity': 'ERROR',
                        'message': f"æšä¸¾ {enum_name} åŒ…å«å¤§å†™å€¼: {uppercase_values}",
                        'line': enum_op['line'],
                        'enum_name': enum_name,
                        'violating_values': uppercase_values,
                        'suggested_fix': f"å°†å€¼æ”¹ä¸ºå°å†™: {[v.lower() for v in uppercase_values]}"
                    })
                
                # æ£€æŸ¥æ˜¯å¦ä¸å·²çŸ¥æšä¸¾å®šä¹‰ä¸€è‡´
                if enum_name in self.known_enums:
                    expected_values = set(self.known_enums[enum_name])
                    actual_values = set(enum_values)
                    
                    missing_values = expected_values - actual_values
                    extra_values = actual_values - expected_values
                    
                    if missing_values or extra_values:
                        issues.append({
                            'type': 'ENUM_DEFINITION_MISMATCH',
                            'severity': 'WARNING',
                            'message': f"æšä¸¾ {enum_name} å®šä¹‰ä¸ä»£ç ä¸ä¸€è‡´",
                            'line': enum_op['line'],
                            'enum_name': enum_name,
                            'missing_values': list(missing_values),
                            'extra_values': list(extra_values),
                            'expected_values': list(expected_values),
                            'actual_values': list(actual_values)
                        })
        
        # æ£€æŸ¥æ•°æ®æ›´æ–°æ“ä½œ
        for data_op in migration_info['data_operations']:
            if data_op['operation'] == 'UPDATE_ENUM_DATA':
                old_value = data_op['old_value']
                new_value = data_op['new_value']
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¤§å°å†™è½¬æ¢
                if old_value.upper() == new_value.upper() and old_value != new_value:
                    issues.append({
                        'type': 'ENUM_CASE_FIX',
                        'severity': 'INFO',
                        'message': f"æ•°æ®è¿ç§»ä¿®å¤äº†æšä¸¾å¤§å°å†™: {old_value} -> {new_value}",
                        'line': data_op['line'],
                        'table_name': data_op['table_name'],
                        'column_name': data_op['column_name'],
                        'old_value': old_value,
                        'new_value': new_value
                    })
        
        return issues

    def analyze_migration_consistency(self) -> Dict[str, Any]:
        """åˆ†æè¿ç§»ä¸€è‡´æ€§"""
        print("ğŸ” åˆ†ææ•°æ®åº“è¿ç§»è„šæœ¬...")
        
        # æŸ¥æ‰¾è¿ç§»æ–‡ä»¶
        migration_files = self.find_migration_files()
        if not migration_files:
            print("âŒ æœªæ‰¾åˆ°è¿ç§»æ–‡ä»¶")
            return {'migration_files': [], 'total_issues': 0}
        
        print(f"âœ… æ‰¾åˆ° {len(migration_files)} ä¸ªè¿ç§»æ–‡ä»¶")
        
        # è§£ææ¯ä¸ªè¿ç§»æ–‡ä»¶
        all_issues = []
        all_enum_operations = []
        all_data_operations = []
        
        for file_path in migration_files:
            print(f"  ğŸ“„ åˆ†æ: {file_path.name}")
            
            migration_info = self.parse_migration_file(file_path)
            self.migration_files.append(migration_info)
            
            if 'error' not in migration_info:
                all_enum_operations.extend(migration_info['enum_operations'])
                all_data_operations.extend(migration_info['data_operations'])
                all_issues.extend(migration_info['potential_issues'])
        
        # ç»Ÿè®¡åˆ†æç»“æœ
        analysis_result = {
            'migration_files': self.migration_files,
            'total_migrations': len(self.migration_files),
            'total_enum_operations': len(all_enum_operations),
            'total_data_operations': len(all_data_operations),
            'total_issues': len(all_issues),
            'enum_operations': all_enum_operations,
            'data_operations': all_data_operations,
            'issues': all_issues
        }
        
        return analysis_result

    def generate_fix_suggestions(self, analysis_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        suggestions = []
        
        # åŸºäºé—®é¢˜ç±»å‹ç”Ÿæˆå»ºè®®
        issues_by_type = {}
        for issue in analysis_result['issues']:
            issue_type = issue['type']
            if issue_type not in issues_by_type:
                issues_by_type[issue_type] = []
            issues_by_type[issue_type].append(issue)
        
        if 'ENUM_CASE_VIOLATION' in issues_by_type:
            suggestions.append("""
## æšä¸¾å¤§å°å†™è§„èŒƒä¿®å¤

å‘ç°è¿ç§»è„šæœ¬ä¸­å®šä¹‰çš„æšä¸¾å€¼ä¸ç¬¦åˆå°å†™è§„èŒƒã€‚

å»ºè®®ï¼š
1. ä¿®æ”¹è¿ç§»è„šæœ¬ï¼Œå°†æšä¸¾å€¼æ”¹ä¸ºå°å†™
2. æ·»åŠ æ•°æ®è¿ç§»æ­¥éª¤ï¼Œæ›´æ–°å·²æœ‰æ•°æ®
3. ç¡®ä¿æ–°å»ºè¡¨æ—¶ä½¿ç”¨æ­£ç¡®çš„æšä¸¾å€¼

ç¤ºä¾‹ä¿®å¤ï¼š
```python
# é”™è¯¯
op.execute("CREATE TYPE parse_status_enum AS ENUM ('UPLOADED', 'PARSING', 'COMPLETED')")

# æ­£ç¡®  
op.execute("CREATE TYPE parse_status_enum AS ENUM ('uploaded', 'parsing', 'completed')")

# æ·»åŠ æ•°æ®ä¿®å¤
op.execute("UPDATE projects SET parse_status = 'uploaded' WHERE parse_status = 'UPLOADED'")
```
""")
        
        if 'ENUM_DEFINITION_MISMATCH' in issues_by_type:
            suggestions.append("""
## æšä¸¾å®šä¹‰ä¸€è‡´æ€§ä¿®å¤

å‘ç°è¿ç§»è„šæœ¬ä¸­çš„æšä¸¾å®šä¹‰ä¸ä»£ç å®šä¹‰ä¸ä¸€è‡´ã€‚

å»ºè®®ï¼š
1. æ£€æŸ¥ä»£ç ä¸­çš„æšä¸¾å®šä¹‰
2. ç¡®ä¿è¿ç§»è„šæœ¬ä¸ä»£ç ä¿æŒåŒæ­¥
3. è€ƒè™‘æ˜¯å¦éœ€è¦æ·»åŠ æˆ–åˆ é™¤æšä¸¾å€¼

ä¿®å¤æ­¥éª¤ï¼š
1. æ¯”å¯¹ä»£ç ä¸­çš„æšä¸¾å®šä¹‰
2. æ›´æ–°è¿ç§»è„šæœ¬ä»¥åŒ¹é…ä»£ç 
3. æµ‹è¯•æ•°æ®å…¼å®¹æ€§
""")
        
        return suggestions

    def print_analysis_report(self, analysis_result: Dict[str, Any]):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æ•°æ®åº“è¿ç§»è„šæœ¬åˆ†ææŠ¥å‘Š")
        print(f"{'='*60}")
        
        # æ€»ä½“ç»Ÿè®¡
        print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"   è¿ç§»æ–‡ä»¶æ•°: {analysis_result['total_migrations']}")
        print(f"   æšä¸¾æ“ä½œæ•°: {analysis_result['total_enum_operations']}")
        print(f"   æ•°æ®æ“ä½œæ•°: {analysis_result['total_data_operations']}")
        print(f"   å‘ç°é—®é¢˜æ•°: {analysis_result['total_issues']}")
        
        # æšä¸¾æ“ä½œè¯¦æƒ…
        if analysis_result['enum_operations']:
            print(f"\nğŸ“‹ æšä¸¾æ“ä½œè¯¦æƒ…:")
            enum_ops_by_type = {}
            for op in analysis_result['enum_operations']:
                op_type = op['operation']
                if op_type not in enum_ops_by_type:
                    enum_ops_by_type[op_type] = []
                enum_ops_by_type[op_type].append(op)
            
            for op_type, ops in enum_ops_by_type.items():
                print(f"   {op_type}: {len(ops)} ä¸ª")
        
        # é—®é¢˜è¯¦æƒ…
        if analysis_result['issues']:
            print(f"\nâŒ å‘ç°çš„é—®é¢˜:")
            issues_by_severity = {'ERROR': [], 'WARNING': [], 'INFO': []}
            
            for issue in analysis_result['issues']:
                severity = issue.get('severity', 'WARNING')
                issues_by_severity[severity].append(issue)
            
            for severity, issues in issues_by_severity.items():
                if issues:
                    severity_icon = {'ERROR': 'ğŸ”´', 'WARNING': 'ğŸŸ¡', 'INFO': 'â„¹ï¸'}[severity]
                    print(f"\n   {severity_icon} {severity} ({len(issues)} ä¸ª):")
                    
                    for issue in issues:
                        print(f"      â€¢ {issue['message']}")
                        if 'suggested_fix' in issue:
                            print(f"        å»ºè®®: {issue['suggested_fix']}")
        
        # ä¿®å¤å»ºè®®
        suggestions = self.generate_fix_suggestions(analysis_result)
        if suggestions:
            print(f"\nğŸ’¡ ä¿®å¤å»ºè®®:")
            for suggestion in suggestions:
                print(suggestion)

    def save_analysis_report(self, analysis_result: Dict[str, Any], output_file: str):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'analysis_result': analysis_result,
            'suggestions': self.generate_fix_suggestions(analysis_result)
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

    def run_analysis(self, verbose: bool = False, save_report: bool = False):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ Excel2Doc æ•°æ®åº“è¿ç§»è„šæœ¬åˆ†æå¼€å§‹...")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ‰§è¡Œåˆ†æ
        analysis_result = self.analyze_migration_consistency()
        
        # æ‰“å°æŠ¥å‘Š
        self.print_analysis_report(analysis_result)
        
        # ä¿å­˜æŠ¥å‘Š
        if save_report:
            report_file = self.project_root / f"migration_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            self.save_analysis_report(analysis_result, str(report_file))
        
        print(f"\nğŸ‰ æ•°æ®åº“è¿ç§»è„šæœ¬åˆ†æå®Œæˆï¼")
        
        return analysis_result['total_issues'] == 0

def main():
    parser = argparse.ArgumentParser(
        description="Excel2Doc æ•°æ®åº“è¿ç§»è„šæœ¬åˆ†æå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python migration_script_analyzer.py                    # åŸºæœ¬åˆ†æ
  python migration_script_analyzer.py --verbose          # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
  python migration_script_analyzer.py --report           # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šæ–‡ä»¶
        """
    )
    
    parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    parser.add_argument('--report', '-r', action='store_true', help='ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šæ–‡ä»¶')
    
    args = parser.parse_args()
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent.parent
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = MigrationScriptAnalyzer(str(project_root))
    success = analyzer.run_analysis(verbose=args.verbose, save_report=args.report)
    
    if not success:
        sys.exit(1)

if __name__ == '__main__':
    main()